---
title: "ML 627 Lab: The Bootstrap & Best Subset Selection"
author: "Rachel Carnes, Britnie Smith"
output: word_document
date: '2022-03-27'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
1. Consider the mpg variable.
a. Find the bootstrap estimate, standard error, and 95% confidence interval for the IQR of mpg.
```{r}
library(readr)
library(dplyr)
library (ISLR2)
library(boot)
library(tidyr)
auto <- read.csv("C:/Users/Rachel Carnes/OneDrive/Class Machine Learning/Week 6/Auto.csv")

auto %>% 
  mutate(horsepower = as.numeric(horsepower))-> auto
auto <- auto[!is.na(auto$horsepower),c(1,4)]
summary(auto)
View(auto)

dim(auto)

IQR(auto$mpg, na.rm = FALSE, type = 7)

IQR.fn <- function(X,index){ 
  return(IQR(X[index]))
}
  
B <- 100 # Number of bootstrap samples
n <- length(auto$mpg) # Sample size (and the size of each bootstrap sample)

  
set.seed(20)
bs.mpg <- boot(auto$mpg, IQR.fn, R=B)
bs.mpg
sd(bs.mpg$t)

# Bootstrap confidence interval
alpha <- 0.05
c(quantile( bs.mpg$t, alpha/2 ),quantile( bs.mpg$t, 1-alpha/2 ))
```

b. Find the bootstrap estimate, standard error, and 95% confidence interval for any other parameter of interest to you about the distribution of mpg. (For example, you could examine the minimum, or the maximum, or the 10th percentile of mpg.)
```{r}


summary(auto$mpg)
min(auto$mpg, na.rm = FALSE)

min.fn <- function(X,index){ 
  return(min(X[index]))
}
  
B <- 100 # Number of bootstrap samples. 
n <- length(auto$mpg) # Sample size (and the size of each bootstrap sample)


  
set.seed(20)
bs.mpg_2 <- boot(auto$mpg, min.fn, R=B)
bs.mpg_2
sd(bs.mpg_2$t)


# Bootstrap confidence interval
alpha <- 0.05
c(quantile( bs.mpg_2$t, alpha/2 ),quantile( bs.mpg_2$t, 1-alpha/2 ))



# Bootstrap samples 1000

IQR(auto$mpg, na.rm = FALSE, type = 7)

IQR.fn <- function(X,index){ 
  return(IQR(X[index]))
}
  
B1 <- 1000 # Number of bootstrap samples
n <- length(auto$mpg) # Sample size (and the size of each bootstrap sample)

  
set.seed(20)
bs.mpg_3 <- boot(auto$mpg, IQR.fn, R=B1)
bs.mpg_3
sd(bs.mpg_3$t)

# Bootstrap confidence interval
alpha <- 0.05
c(quantile( bs.mpg_3$t, alpha/2 ),quantile( bs.mpg_3$t, 1-alpha/2))


# Bootstrap Samples 10000
IQR(auto$mpg, na.rm = FALSE, type = 7)

IQR.fn <- function(X,index){ 
  return(IQR(X[index]))
}
  
B2 <- 10000 # Number of bootstrap samples
n <- length(auto$mpg) # Sample size (and the size of each bootstrap sample)

  
set.seed(20)
bs.mpg_4 <- boot(auto$mpg, IQR.fn, R=B2)
bs.mpg_4
sd(bs.mpg_4$t)

# Bootstrap confidence interval
alpha <- 0.05
c(quantile( bs.mpg_4$t, alpha/2 ),quantile( bs.mpg_4$t, 1-alpha/2 ))
```

2. Consider modeling mpg using a quadratic (polynomial of degree = 2) relationship with horsepower.

a. Plot the least squares estimate of the quadratic relationship along with the observed data.


```{r}
 
auto %>%
mutate(horsepower2 = horsepower^2) ->auto2
auto2

lm_auto <- lm_traincube1 <- lm(mpg ~ horsepower + horsepower2 , data = auto2)
lm_auto
plot(lm_auto)





```

b. Plot B = 100 bootstrap estimates of the relationship (evaluated at the observed values of horsepower).
```{r}

slopes.fn <- function(dataset,index){
  coefs <- coef(lm(mpg ~ horsepower + horsepower2, data=auto2[index, ]))
  return(coefs)
}

slopes.fn(auto2,sample(n,10))


  
B <- 100 # Number of bootstrap samples.  
n <- length(auto2) # Sample size (and the size of each bootstrap sample)

set.seed(30)
bs.reg <- boot(Auto, slopes.fn, R=B) # This may take a while to run with our current B. 
head(bs.reg$t)


# Bootstrap confidence interval
alpha <- 0.05
c(quantile( bs.mpg_5$t, alpha/2 ),quantile( bs.mpg_5$t, 1-alpha/2 ))


```

3. Consider now a model to predict mpg (or a transformation of mpg) using the eight other features (variables) in the data set.
 
```{r}
library(GGally)
library(broom)
library(tidyverse)

auto2 <- read.csv("C:/Users/Rachel Carnes/OneDrive/Class Machine Learning/Week 6/Auto.csv")
auto2 %>% 
  mutate(horsepower = as.numeric(horsepower)) %>%
  select(-name)-> auto3
View(auto3)
ggpairs(auto3)

fit.auto <- lm(mpg ~ weight + horsepower + cylinders + displacement + acceleration + year + origin , auto3)
summary(fit.auto)

aout1 <- augment(fit.auto)
qplot(x = .fitted, y= .resid, data = aout1) +geom_hline(yintercept = 0)

# Transformed mpg

auto3 %>%
  mutate(mpg2 = log(mpg)) -> auto4

View(auto4)
ggpairs(auto4)

fit.auto2 <- lm(mpg2 ~ weight + horsepower + cylinders + displacement + acceleration + year + origin , auto4)
summary(fit.auto2)

aout2 <- augment(fit.auto2)
qplot(x = .fitted, y= .resid, data = aout2) +geom_hline(yintercept = 0)


```

a. Conduct preliminary exploratory analyses to determine if any adjustments need to be made to meet the assumptions of the multiple linear regression model. Briefly summarize what adjustments you are making to any variables and why. Do not include any output here. Just state what you examined and your corresponding final adjustments.

Looking at the full data set we are seeing that there is curvature and unequal variance. This is showing us that we do need to transform some variables. We decided to transform mpg(the response). We logged mpg to reduce the variance and curvature. 


```{r}

```

b. Incorporate any adjustments from part (a). Use the regsubsets() function in the leaps library to perform best subset selection in order to choose the best model.
```{r}

library(leaps)
?regsubsets
regfit_full <- regsubsets(mpg ~ ., data = auto3)

summary (regfit_full)

res.sum <- summary(regfit_full)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)


par(mfrow = c(2,2))
plot(res.sum$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")

plot(res.sum$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "l")
which.max(res.sum$adjr2) # just adding a point at the optimal value
points(6, res.sum$adjr2[6], col = "red", cex = 2, pch = 20)

plot(res.sum$cp, xlab = "Number of Variables",ylab = "Cp", type = "l")
which.min(res.sum$cp)
points(6, res.sum$cp[6], col = "red", cex = 2,pch = 20)

plot(res.sum$bic, xlab = "Number of Variables",ylab = "BIC", type = "l")
which.min(res.sum$bic)
points(3, res.sum$bic[3], col = "red", cex = 2,  pch = 20)





```

i. What is the best model obtained according to the Cp criterion?
  According to Cp the best model has 6 variables which are cylinders, displacement, horsepower, weight, year, and origin. It removed acceleration. 

ii. What is the best model obtained according to the BIC criterion?
  According to BIC the best model has 3 variables which are weight, year, and origin. It removed cylinders, displacement, horsepower, acceleration.

iii. What is the best model obtained according to the adjusted-R 2 criterion?
  According to Adjusted-R2 the best model has 6 variables which are cylinders, displacement, horsepower, weight, year, origin. It removed acceleration. 

iv. Provide plots as evidence for your choices.
```{r}

par(mfrow=c(1,1))
plot(regfit_full, scale = "r2")
plot(regfit_full, scale = "adjr2")
plot(regfit_full, scale = "Cp")
plot(regfit_full, scale = "bic")


par (mfrow = c(2, 2))
plot (reg.summary$rss , xlab = " Number of Variables ",
ylab = " RSS ", type = "l")

plot (reg.summary$adjr2 , xlab = " Number of Variables ",
ylab = " Adjusted RSq ", type = "l")
```

c. Compare the results in (b) to those from forward stepwise selection and backwards stepwise selection.

Forward Stepwise is giving us an RSS or ... and and R^2 of ... Keep in mind this is not the best to use when finding the best possible model because it fails to select the best possible two variable model. 

Backward stepwise is giving us an RSS of ... and an R^2 or...This requires that the number of samples,n, be larger than the number of variables,p. 
```{r}

regfit.fwd <- regsubsets(mpg ~ ., data = auto3, nvmax = 19, method = "forward")
summary(regfit.fwd)


regfit.bwd <- regsubsets(mpg ~ ., data = auto3,nvmax = 19, method = "backward")
summary(regfit.bwd)

```

